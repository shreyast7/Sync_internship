# -*- coding: utf-8 -*-
"""chatbot_ai.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1annQ1d1xjPS7PhVk-PM8-fqgB-UoiCDC

Import the required libraries
"""

import numpy as np
import nltk
nltk.download('omw-1.4')
import string
import random

"""Importing and reading the corpus"""

f=open('chatbot.txt','r',errors='ignore')
raw_doc=f.read()
raw_doc=raw_doc.lower() #Coverts text to lowercase
nltk.download('punkt') #Using the Punkt tokenizer
nltk.download('wordnet')#Using the wordnet dictionary
sentence_tokens=nltk.sent_tokenize(raw_doc) #Converts doc to list of sentences
word_tokens=nltk.word_tokenize(raw_doc) #Coverts doc to list of words

from google.colab import drive
drive.mount('/content/drive')

"""Example of sentence tokens"""

sentence_tokens[2]

""" Example of word tokens"""

word_tokens[:2]

"""Text preprocessing"""

lemmer=nltk.stem.WordNetLemmatizer()
#Wordnet is a semantically-oriented dictionary of english included in NLTK.
def LemTokens(tokens):
   return [lemmer.lemmatize(token) for token in tokens]
remove_punct_dict=dict((ord(punct), None) for punct in string.punctuation)
def LemNormalize(text):
   return LemTokens(nltk.word_tokenize(text.lower().translate(remove_punct_dict)))

"""Defining the greeting function"""

greet_inputs=("hello","hi","greetings","sup","what's up","hey", )
greet_responses=["hi","hey","nods","hi there","hello","I am glad! You are talking to me"]
def greet(sentence):

  for word in sentence.split():
     if word.lower() in greet_inputs:
         return random.choice(greet_responses)

"""Responses generation"""

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

def response(user_response):
  robo1_response=''
  TfidfVec=TfidfVectorizer(tokenizer=LemNormalize,stop_words='english')
  tfidf=TfidfVec.fit_transform(sentence_tokens)
  vals=cosine_similarity(tfidf[-1],tfidf)
  idx=vals.argsort()[0][-2]
  flat=vals.flatten()
  flat.sort()
  req_tfidf=flat[-2]
  if(req_tfidf==0):
    robo1_response=robo1_response+"I am sorry! I don't understand you"
    return robo1_response
  else:
    robo1_response=robo1_response,sentence_tokens[idx]
    return robo1_response

"""Defining conversion start/end protocols"""

flag=True
print("BOT: My name is Stark. Let's have a conversion! Also,if you want to exit any time,just type Bye!")
while(flag==True):
   user_response=input()
   user_response=user_response.lower()
   if(user_response!= 'bye'):
        if(user_response=='thanks'or user_response=='thank you'):
          flag=False
          print('BOT: You are welcome..')
        else:
           if(greet(user_response) !=None):
              print('BOT: '+ greet(user_response))
           else:
             sentence_tokens.append(user_response)
             word_tokens= word_tokens + nltk.word_tokenize(user_response)
             final_words= list(set(word_tokens))
             print("BOT:" , end= ' ')
             print(response(user_response))
             sentence_tokens.remove(user_response)
   else: 
        flag=False
        print("BOT: Goodbye! Take care")

